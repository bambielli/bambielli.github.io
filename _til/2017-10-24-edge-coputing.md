---
title:  "Edge Computing"
date:   2017-10-24 22:00:00
category: til
tags: ["cloud", "edge", "IoT", "distributed", "system", "systems", "data", "optimization"]
---

TIL about edge computing, and how it can lead to optimizations over cloud computing in certain scenarios.

This week started my onboarding at [Uptake][up]{:target="_blank"} here in Chicago. Uptake is a predictive analytics software company, focused on providing actionable insights to industrial companies on how to maintain and optimize their fleets.

Uptake is by nature a data company. A quote from Uptake's IoT director: "Data is like the Oil of the 21st century. It requires cleaning and processing to make it valuable." We ingest data from our partners, process that data, and return insights that provide economic value at scale.

## Cloud Computing

`Cloud computing` has been all the rage for the past 10 or so years. Through the magic of distributed systems and virtualization mechanisms, companies can host their applications and data "in the cloud", meaning the infrastructure on which the application runs and on which data is persisted is not physically on premise. This type of architecture has many cost saving, scaling, and maintenance advantages (to name a few).

Most of the applications exposed to the public internet are, as of this writing, hosted on the [Amazon Web Services][aws]{:target="_blank"} (AWS) cloud environment. Microsoft offers its [Azure][azure]{:target="_blank"} cloud, Google has [Google Cloud Platform][gcp]{:target="_blank"} (GCP). Regardless of which platform you choose to deploy your apps on and host your data, the underlying cloud concepts are identical.

## An Unexpected Disadvantage

A disadvantage of cloud computing that I never considered until onboarding this week, is in the case when the source of data is not the app itself, but is **some other disconnected source**.

An example in the case of Uptake's Rail partners is a locomotive that generates up to a Terabyte of data a week through its various sensors. If Uptake hosts its data processing code in the cloud, **this massive amount of data would need to be transferred to the cloud environment** for it to be ingested by our intake systems.

Contrast this with a traditional webapp, like Facebook: all the data generated by Facebook users happens through direct interaction with their web application. **No additional transfer of data is necessary**, since data generation is co-located to where application and data processing code is hosted.

Since Uptake works with Internet connected devices (IoT devices) like locomotives, wind turbines, and construction equipment, **transferring and processing data that doesn't result in actionable insights or economic value for our customers is wasted work on our end.**

We can do better, though.

## Edge Computing

Enter `edge computing`. Edge computing brings the code necessary to process the data generated by IoT devices **out of the cloud and on to the device itself.**

This has become possible over the past 5-8 years, as the cost of microprocessors and memory has dropped substantially while performance has increased. The economics of computing infrastructure has made edge computing a reality, where only cloud computing may have been possible in the past due to the infrastructure demands of data processing apps.

Edge computing **prevents the transfer of data off-device that would not result in actionable insights**. Any insight detected through on-device computing like anomalies or changes in condition, can still be sent to the cloud for reporting and visualization purposes.

I'm excited to learn more about IoT and our Data Science efforts as I continue to ramp up at Uptake!

[up]: uptake.com
[gcp]: https://cloud.google.com/
[azure]: https://azure.microsoft.com/en-us/
[aws]: https://aws.amazon.com/
